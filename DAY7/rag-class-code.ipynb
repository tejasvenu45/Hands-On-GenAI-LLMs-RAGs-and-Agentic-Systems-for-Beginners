{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Code reference: Huggingface https://huggingface.co/ngxson/demo_simple_rag_py/blob/main/demo.py\n",
        "\n",
        "Txt file source: Wikipedia https://en.wikipedia.org/wiki/Smartphone"
      ],
      "metadata": {
        "id": "lt8fGaI5U5zn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyeJ7DE8FJPu"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "with open('smartphones.txt', 'r', encoding='utf-8') as file:\n",
        "    dataset = [line.strip() for line in file if line.strip()]\n",
        "print(f\"Loaded {len(dataset)} entries\")"
      ],
      "metadata": {
        "id": "wOxhow2uFN5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "amut7ARTKr30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "LANGUAGE_MODEL = \"google-t5/t5-base\"\n",
        "\n",
        "embedder = SentenceTransformer(EMBEDDING_MODEL) # a sentence embedding model\n",
        "tokenizer = T5Tokenizer.from_pretrained(LANGUAGE_MODEL)\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(LANGUAGE_MODEL)"
      ],
      "metadata": {
        "id": "sKUlZxXVKlWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VECTOR_DB = []  # (chunk, embedding)\n",
        "\n",
        "def add_chunk_to_db(chunk):\n",
        "    embedding = embedder.encode(chunk)\n",
        "    VECTOR_DB.append((chunk, embedding))\n",
        "\n",
        "for i, chunk in enumerate(dataset):\n",
        "    add_chunk_to_db(chunk)\n",
        "    print(f\"Added chunk {i+1}/{len(dataset)} to database\")"
      ],
      "metadata": {
        "id": "CKXmsDAtLqog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VECTOR_DB[0]"
      ],
      "metadata": {
        "id": "kKhcu1tSNkVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(a, b):\n",
        "    dot = np.dot(a, b)\n",
        "    norm_a = np.linalg.norm(a)\n",
        "    norm_b = np.linalg.norm(b)\n",
        "    return dot / (norm_a * norm_b)"
      ],
      "metadata": {
        "id": "lkj83-HrLv8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieval\n",
        "def retrieve(query, top_n=3):\n",
        "    query_emb = embedder.encode(query)\n",
        "    sims = [(chunk, cosine_similarity(query_emb, emb)) for chunk, emb in VECTOR_DB]\n",
        "    sims.sort(key=lambda x: x[1], reverse=True)\n",
        "    return sims[:top_n]"
      ],
      "metadata": {
        "id": "i6ePjJCLL05s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"Ask me a question: \")\n",
        "retrieved = retrieve(query)\n",
        "\n",
        "print(\"\\nRetrieved knowledge:\")\n",
        "for chunk, sim in retrieved:\n",
        "    print(f\" - (similarity: {sim:.2f}) {chunk}\")"
      ],
      "metadata": {
        "id": "KeMvoydpL4_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# augmentation\n",
        "context = \"\\n\".join([f\"- {chunk}\" for chunk, _ in retrieved])\n",
        "prompt = f\"\"\"\n",
        "You are a helpful chatbot. Use only the following information to answer the question.\n",
        "Do not add extra knowledge.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# generation\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "outputs = t5_model.generate(**inputs, max_new_tokens=128)\n",
        "\n",
        "print(\"\\nChatbot response:\")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "NT42jJFeL7JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sSA_W4ocMF01"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}